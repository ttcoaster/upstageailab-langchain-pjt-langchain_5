"""
CLI RAG ì‹œìŠ¤í…œ

webuiì™€ ë™ì¼í•œ RAG ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ í•˜ë“œì½”ë”©ëœ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” CLI ë„êµ¬ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- webuiì™€ ë™ì¼í•œ RAG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
- í•˜ë“œì½”ë”©ëœ ì§ˆë¬¸ ì²˜ë¦¬
- ë©”ëª¨ë¦¬ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬ (DB ì €ì¥ ì—†ìŒ)
- ê²€ìƒ‰ëœ ë¬¸ì„œ ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from langchain_upstage import UpstageEmbeddings
from typing import List, Dict

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€ (ì´ë¯¸ code í´ë” ì•ˆì— ìˆìŒ)
script_dir = Path(__file__).parent.absolute()
if str(script_dir) not in sys.path:
    sys.path.insert(0, str(script_dir))

# ëª¨ë“ˆ import
from modules import VectorStoreManager, LLMManager, RetrieverManager

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(script_dir / '.env')


class SimpleChatHistory:
    """ë©”ëª¨ë¦¬ ê¸°ë°˜ ê°„ë‹¨í•œ ëŒ€í™” ê´€ë¦¬ í´ë˜ìŠ¤ (DB ì €ì¥ ì—†ìŒ)"""
    
    def __init__(self):
        self.messages = []
    
    def add_user_message(self, content: str):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({"role": "user", "content": content})
    
    def add_ai_message(self, content: str):
        """AI ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({"role": "assistant", "content": content})
    
    def get_chat_history_as_dicts(self) -> List[Dict]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        return self.messages.copy()


def initialize_rag_system():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (webuiì™€ ë™ì¼í•œ ë°©ì‹)"""
    try:
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        embeddings = UpstageEmbeddings(
            api_key=os.getenv("UPSTAGE_API_KEY"),
            model="embedding-query"
        )
        
        # ë²¡í„°ìŠ¤í† ì–´ ê´€ë¦¬ì ì´ˆê¸°í™” (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
        current_dir = Path(__file__).parent.parent.absolute()  # code í´ë”ì˜ ë¶€ëª¨ í´ë”
        pdf_dir = str(current_dir / "data" / "pdf")
        vectorstore_dir = str(current_dir / "data" / "vectorstore")
        
        vector_manager = VectorStoreManager(
            pdf_dir=pdf_dir,
            vectorstore_dir=vectorstore_dir, 
            embeddings=embeddings,
            chunk_size=1000,
            chunk_overlap=50
        )
        
        # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ/ìƒì„±
        vectorstore = vector_manager.get_or_create_vectorstore()
        
        if vectorstore is None:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None
        
        print("âœ… ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # LLM ê´€ë¦¬ì ì´ˆê¸°í™”
        llm_manager = LLMManager()
        print("âœ… LLM ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê²€ìƒ‰ê¸° ê´€ë¦¬ì ì´ˆê¸°í™”
        retriever_manager = RetrieverManager(vectorstore=vectorstore)
        print("âœ… ê²€ìƒ‰ê¸° ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
        
        return llm_manager, retriever_manager, vector_manager
    
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return None, None, None


def process_question(question: str, llm_manager, retriever_manager, chat_history):
    """ì§ˆë¬¸ ì²˜ë¦¬ ë° RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print(f"\nğŸ“ ì§ˆë¬¸: {question}")
    print("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
    
    try:
        # ë¬¸ì„œ ê²€ìƒ‰
        documents = retriever_manager.search_documents(question)
        context = retriever_manager.format_documents_for_context(documents)
        
        if not documents:
            print("âš ï¸  ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“„ {len(documents)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
        sources = retriever_manager.get_unique_sources(documents)
        if sources:
            print("ğŸ“š ì°¸ì¡° ë¬¸ì„œ:")
            for source in sources:
                print(f"   â€¢ {source}")
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        chat_history_dicts = chat_history.get_chat_history_as_dicts()
        
        print("\nğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...")
        
        # LLM ì‘ë‹µ ìƒì„±
        response = llm_manager.generate_response(
            question=question,
            context=context,
            chat_history=chat_history_dicts
        )
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        chat_history.add_user_message(question)
        chat_history.add_ai_message(response)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ¤– AI ë‹µë³€:")
        print("="*80)
        print(response)
        print("="*80)
        
        return response
        
    except Exception as e:
        print(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¯ CLI RAG ì‹œìŠ¤í…œ ì‹œì‘")
    print("="*50)
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    llm_manager, retriever_manager, vector_manager = initialize_rag_system()
    
    if not all([llm_manager, retriever_manager, vector_manager]):
        print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ë©”ëª¨ë¦¬ ê¸°ë°˜ ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”
    chat_history = SimpleChatHistory()
    
    # í•˜ë“œì½”ë”©ëœ ì§ˆë¬¸
    hardcoded_question = "ì œê³¼ì œë¹µì—ì„œ ë°˜ì£½ ì˜¨ë„ ê´€ë¦¬ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    
    print("\nâœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    print("ğŸ’¬ í•˜ë“œì½”ë”©ëœ ì§ˆë¬¸ìœ¼ë¡œ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì§ˆë¬¸ ì²˜ë¦¬
    response = process_question(hardcoded_question, llm_manager, retriever_manager, chat_history)
    
    if response:
        print(f"\nâœ… ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š í˜„ì¬ ëŒ€í™” ê¸°ë¡: {len(chat_history.messages)}ê°œ ë©”ì‹œì§€")
    else:
        print("\nâŒ ì§ˆë¬¸ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    print("\nğŸ CLI RAG ì‹œìŠ¤í…œ ì¢…ë£Œ")


if __name__ == "__main__":
    main()